name: ğŸ¤– Crawler Automatique Immobilier
on:
  schedule:
    # ExÃ©cution 2 fois par jour (heures UTC)
    - cron: '0 5 * * *'   # 7h00 heure franÃ§aise (UTC+2)
    - cron: '0 17 * * *'  # 19h00 heure franÃ§aise (UTC+2)
  
  # Permet le lancement manuel depuis GitHub
  workflow_dispatch:
    inputs:
      force_run:
        description: 'Forcer l\'exÃ©cution du crawler'
        required: false
        default: 'true'

jobs:
  run-crawler:
    runs-on: ubuntu-latest
    name: ğŸ  Lancer le Crawler SeLoger
    
    steps:
      - name: ğŸ“‹ Informations d'exÃ©cution
        run: |
          echo "ğŸ• Heure d'exÃ©cution: $(date)"
          echo "ğŸŒ Fuseau horaire: $(timedatectl show --property=Timezone --value)"
          echo "ğŸ¯ DÃ©clenchement du crawler immobilier..."

      - name: ğŸš€ DÃ©clencher le crawler Supabase
        run: |
          # GÃ©nÃ©rer un UUID pour le job
          JOB_ID=$(uuidgen)
          echo "ğŸ“ Job ID: $JOB_ID"
          
          # Appeler la fonction Edge Supabase
          RESPONSE=$(curl -s -w "\n%{http_code}" -X POST \
            -H "Authorization: Bearer ${{ secrets.SUPABASE_SERVICE_KEY }}" \
            -H "Content-Type: application/json" \
            -d "{\"job_id\": \"$JOB_ID\"}" \
            https://veoynqppumqslocvtzvk.supabase.co/functions/v1/crawler-annonces)
          
          # Extraire le code de statut HTTP
          HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
          BODY=$(echo "$RESPONSE" | head -n -1)
          
          echo "ğŸ“¡ Code de rÃ©ponse: $HTTP_CODE"
          echo "ğŸ“Š RÃ©ponse: $BODY"
          
          # VÃ©rifier le succÃ¨s
          if [ "$HTTP_CODE" -eq 200 ]; then
            echo "âœ… Crawler lancÃ© avec succÃ¨s!"
            echo "ğŸ”„ Le processus s'exÃ©cute maintenant en arriÃ¨re-plan sur Supabase"
          else
            echo "âŒ Erreur lors du lancement du crawler"
            echo "ğŸ“‹ DÃ©tails: $BODY"
            exit 1
          fi

      - name: ğŸ“Š VÃ©rifier le statut (optionnel)
        run: |
          echo "â„¹ï¸ Le crawler s'exÃ©cute maintenant de maniÃ¨re asynchrone"
          echo "ğŸ“ˆ Vous pouvez suivre les progrÃ¨s dans votre interface web"
          echo "ğŸ—„ï¸ Les rÃ©sultats seront visibles dans la table 'annonces'"
          echo "ğŸ“ Les logs dÃ©taillÃ©s sont dans la table 'crawler_jobs'"

      - name: ğŸ‰ RÃ©sumÃ© d'exÃ©cution
        run: |
          echo "=================================="
          echo "ğŸ¤– CRAWLER AUTOMATIQUE EXÃ‰CUTÃ‰"
          echo "=================================="
          echo "â° Prochaine exÃ©cution automatique:"
          echo "   â€¢ Matin: 7h00 (heure franÃ§aise)"
          echo "   â€¢ Soir: 19h00 (heure franÃ§aise)"
          echo "ğŸ”„ FrÃ©quence: 2 fois par jour, 7j/7"
          echo "ğŸ’» Fonctionne mÃªme PC Ã©teint"
          echo "=================================="
